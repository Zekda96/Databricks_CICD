{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6674e8e9-4328-4a8b-9673-df6e538df585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG adventureworks\")\n",
    "spark.sql(\"USE SCHEMA bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af5de75b-ff16-4029-9880-b82f97d127b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read External Storage path from Key Vault\n",
    "blob_path = dbutils.secrets.get(scope=\"adventureworks-secret-scope\", key=\"adventureworks-external-location\")\n",
    "\n",
    "# Read source file from External Storage (Data Lake)\n",
    "source_path = f\"{blob_path}/Sales SalesOrderHeader.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b9e19c9-88e3-4bda-927a-74614cd42073",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.removeAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1de09981-f6bb-4b5b-9f21-3a7d1f0fa93b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create widgets\n",
    "dbutils.widgets.text(\"bronze_schema\", \"adventureworks.bronze\", \"Bronze Schema\")\n",
    "\n",
    "# Retrieve values\n",
    "bronze_schema = dbutils.widgets.get(\"bronze_schema\")\n",
    "bronze_table = bronze_schema + \".sales_order_header\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c3b4d96-713d-48b2-9f6f-aee679769d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read CSV file into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd79375a-6684-4c0a-98d2-52c94fbf336f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762913963942}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import current_timestamp, to_utc_timestamp\n",
    "\n",
    "# Define schema\n",
    "sales_schema = StructType([\n",
    "    StructField(\"sales_order_id\", IntegerType(), False),\n",
    "    StructField(\"revision_number\", IntegerType(), False),\n",
    "    StructField(\"order_date\", TimestampType(), False),\n",
    "    StructField(\"due_date\", TimestampType(), False),\n",
    "    StructField(\"ship_date\", TimestampType(), False),\n",
    "    StructField(\"status\", IntegerType(), False),\n",
    "    StructField(\"online_order_flag\", IntegerType(), False),\n",
    "    StructField(\"sales_order_number\", StringType(), False),\n",
    "    StructField(\"purchase_order_number\", StringType(), False),\n",
    "    StructField(\"account_number\", StringType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"sales_person_id\", IntegerType(), False),\n",
    "    StructField(\"territory_id\", IntegerType(), False),\n",
    "    StructField(\"bill_to_address_id\", IntegerType(), False),\n",
    "    StructField(\"ship_to_address_id\", IntegerType(), False),\n",
    "    StructField(\"ship_method_id\", IntegerType(), False),\n",
    "    StructField(\"credit_card_id\", IntegerType(), False),\n",
    "    StructField(\"credit_card_approval_code\", StringType(), False),\n",
    "    StructField(\"currency_rate_id\", IntegerType(), False),\n",
    "    StructField(\"sub_total\", DoubleType(), False),\n",
    "    StructField(\"tax_amt\", DoubleType(), False),\n",
    "    StructField(\"freight\", DoubleType(), False),\n",
    "    StructField(\"total_due\", DoubleType(), False),\n",
    "    StructField(\"comment\", StringType(), False),\n",
    "    StructField(\"rowguid\", StringType(), False),\n",
    "    StructField(\"modified_date\", TimestampType(), False)\n",
    "])\n",
    "\n",
    "# Load the CSV using the defined schema\n",
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"delimiter\", \",\")\n",
    "    .schema(sales_schema)\n",
    "    .load(source_path)\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"ingestion_timestamp_utc\", to_utc_timestamp(current_timestamp(), \"UTC\"))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a039c059-6de0-46b1-9ef0-5cd36e0b1d98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Upsert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64a198f-100b-402e-a20e-06da1dc0c6e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Get a reference to the Delta table\n",
    "delta_table = DeltaTable.forName(spark, bronze_table)\n",
    "\n",
    "# Count rows before merge\n",
    "before_count = spark.table(bronze_table).count()\n",
    "print(f\"Rows before merge: {before_count}\")\n",
    "\n",
    "# Perform merge (upsert) operation\n",
    "(\n",
    "    delta_table.alias(\"target\")\n",
    "    .merge(\n",
    "        df.alias(\"source\"),\n",
    "        \"target.sales_order_id = source.sales_order_id\"\n",
    "    )\n",
    "    .whenMatchedUpdateAll()\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "# Count rows after merge\n",
    "after_count = spark.table(bronze_table).count()\n",
    "print(f\"Rows after merge: {after_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2031f51b-e60a-4ebd-9de0-4ddfda92ca43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "most_recent_row = spark.table(bronze_table).orderBy(desc(\"ingestion_timestamp_utc\")).limit(1)\n",
    "display(most_recent_row)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ingest_sales_order_header",
   "widgets": {
    "bronze_schema": {
     "currentValue": "adventureworks.bronze",
     "nuid": "cc2d8190-6ab4-4d90-9a0e-4df5fcc04aea",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "adventureworks.bronze",
      "label": "Bronze Schema",
      "name": "bronze_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "adventureworks.bronze",
      "label": "Bronze Schema",
      "name": "bronze_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
